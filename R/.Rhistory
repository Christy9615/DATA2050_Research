#add_constraint(p_il[i,l] - z_kl[k,l] - z_ik[i,k] >= -1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# Each i have exactly one probs
add_constraint(sum_over(p_il[i,l], l=1:length(PI)) == 1, i=1:n) %>%
#Penalty Expression
#add_variable(lambda[j],j=1:p,type = 'binary') %>%
#add_constraint(beta[j] <= M*lambda[j], j=1:p) %>%
#add_constraint(beta[j] <= -M*lambda[j], j=1:p) %>%
# Objective Function
set_objective(  - (sum_over(y[i] * log(PI[l]) * p_il[i,l] + (1-y[i]) * log(1-PI[l]) * p_il[i,l],i=1:n,l=1:length(PI)))
,sense = "min") %>%
solve_model(with_ROI(solver = "glpk"))
MILP_V2
#
zik <- MILP_V2 %>% get_solution(z_ik[i,k])
#
zik <- MILP_V2 %>% get_solution(z_ik[i,k])
files <- list.files("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data")
df <- read.csv(paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data/",files[10]))
# Set data matrix
# works out fine for 1:5, errors when trying yo increase sample size
#df <- df[1:10,1:5]
y <- df[[1]]
X <- as.matrix(df[,2:ncol(df)])
# Warm start solution
n = nrow(X)
p = ncol(X)
M = 1000 #
Lambda0 = 0
# Score Pool
SK_pool <- c((-5*p) : (5*p)) # Determined by lb and ub of beta
# Probability pool
PI <- seq(0,1,length=100) # Equally spaced between 0,1, length = 100
# Delete 0 and 1 so that obj can take log
PI <- PI[-c(1,100)]
t1 = Sys.time()
# Model description
MILP_V2 <- MIPModel() %>%
# Integer coefficients for attributes
add_variable(beta[j], j=1:p, type = 'integer') %>%
# Predicted Risk Score from the integer coefficients
add_variable(s[i], i= 1:n, type = 'integer') %>%
# Exchanged this line on 11.8.2023
add_constraint(sum_over(beta[j]*X[i,j], j=1:p) - s[i] == 0,i=1:n) %>%
# Indicator of S_i = k, k: one potential score from the score pool
add_variable(z_ik[i,k], i=1:n, k=1:length(SK_pool), type = 'binary') %>%
add_constraint(sum_over(z_ik[i,k], k = 1:length(SK_pool)) == 1, i=1:n) %>%
# old
add_constraint(s[i] - SK_pool[k] <= M * (1-z_ik[i,k]), i=1:n,k=1:length(SK_pool)) %>%
add_constraint(s[i] - SK_pool[k] >= -M * (1-z_ik[i,k]), i=1:n,k=1:length(SK_pool)) %>%
# new
#add_constraint((1-z_ik[i,k]) / (s[i] - SK_pool[k]) <= 1/M , i=1:n,k=1:length(SK_pool)) %>%
#add_constraint((1-z_ik[i,k]) / (s[i] - SK_pool[k]) >= -1/M, i=1:n,k=1:length(SK_pool)) %>%
# Indicator of score k assigned to prob pi_l
add_variable(z_kl[k,l], k=1:length(SK_pool), l=1:length(PI), type = 'binary') %>%
# each k is assigened to exactly 1 probs
add_constraint(sum_over(z_kl[k,l], l=1:length(PI)) == 1,k=1:length(SK_pool)) %>%
# Indicator of point i assigned with prob pi_l
add_variable(p_il[i,l], i=1:n, l=1:length(PI),type = 'binary') %>%
# old
add_constraint(p_il[i,l] >= z_kl[k,l] + z_ik[i,k] - 1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# new
#add_constraint(p_il[i,l] - z_kl[k,l] - z_ik[i,k] >= -1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# Each i have exactly one probs
add_constraint(sum_over(p_il[i,l], l=1:length(PI)) == 1, i=1:n) %>%
#Penalty Expression
#add_variable(lambda[j],j=1:p,type = 'binary') %>%
#add_constraint(beta[j] <= M*lambda[j], j=1:p) %>%
#add_constraint(beta[j] <= -M*lambda[j], j=1:p) %>%
# Objective Function
set_objective(  - (sum_over(y[i] * log(PI[l]) * p_il[i,l] + (1-y[i]) * log(1-PI[l]) * p_il[i,l],i=1:n,l=1:length(PI)))
,sense = "min") %>%
solve_model(with_ROI(solver = "glpk"))
library(ompr) # Package for establish OMPR Model
library(ompr.roi) # Solver package
library(ROI.plugin.glpk) # Specific solver used
library(tidyverse)
source('risk.R')
# MILP Version 2
# Testing run with smaller sample sized datasets
# Small data stored at small_data
files <- list.files("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data")
df <- read.csv(paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data/",files[10]))
# Set data matrix
# works out fine for 1:5, errors when trying yo increase sample size
df <- df[1:10,1:5]
y <- df[[1]]
X <- as.matrix(df[,2:ncol(df)])
# Warm start solution
n = nrow(X)
p = ncol(X)
M = 1000 #
Lambda0 = 0
# Score Pool
SK_pool <- c((-5*p) : (5*p)) # Determined by lb and ub of beta
# Probability pool
PI <- seq(0,1,length=100) # Equally spaced between 0,1, length = 100
# Delete 0 and 1 so that obj can take log
PI <- PI[-c(1,100)]
t1 = Sys.time()
# Model description
MILP_V2 <- MIPModel() %>%
# Integer coefficients for attributes
add_variable(beta[j], j=1:p, type = 'integer') %>%
# Predicted Risk Score from the integer coefficients
add_variable(s[i], i= 1:n, type = 'integer') %>%
# Exchanged this line on 11.8.2023
add_constraint(sum_over(beta[j]*X[i,j], j=1:p) - s[i] == 0,i=1:n) %>%
# Indicator of S_i = k, k: one potential score from the score pool
add_variable(z_ik[i,k], i=1:n, k=1:length(SK_pool), type = 'binary') %>%
add_constraint(sum_over(z_ik[i,k], k = 1:length(SK_pool)) == 1, i=1:n) %>%
# old
add_constraint(s[i] - SK_pool[k] <= M * (1-z_ik[i,k]), i=1:n,k=1:length(SK_pool)) %>%
add_constraint(s[i] - SK_pool[k] >= -M * (1-z_ik[i,k]), i=1:n,k=1:length(SK_pool)) %>%
# new
#add_constraint((1-z_ik[i,k]) / (s[i] - SK_pool[k]) <= 1/M , i=1:n,k=1:length(SK_pool)) %>%
#add_constraint((1-z_ik[i,k]) / (s[i] - SK_pool[k]) >= -1/M, i=1:n,k=1:length(SK_pool)) %>%
# Indicator of score k assigned to prob pi_l
add_variable(z_kl[k,l], k=1:length(SK_pool), l=1:length(PI), type = 'binary') %>%
# each k is assigened to exactly 1 probs
add_constraint(sum_over(z_kl[k,l], l=1:length(PI)) == 1,k=1:length(SK_pool)) %>%
# Indicator of point i assigned with prob pi_l
add_variable(p_il[i,l], i=1:n, l=1:length(PI),type = 'binary') %>%
# old
add_constraint(p_il[i,l] >= z_kl[k,l] + z_ik[i,k] - 1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# new
#add_constraint(p_il[i,l] - z_kl[k,l] - z_ik[i,k] >= -1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# Each i have exactly one probs
add_constraint(sum_over(p_il[i,l], l=1:length(PI)) == 1, i=1:n) %>%
#Penalty Expression
#add_variable(lambda[j],j=1:p,type = 'binary') %>%
#add_constraint(beta[j] <= M*lambda[j], j=1:p) %>%
#add_constraint(beta[j] <= -M*lambda[j], j=1:p) %>%
# Objective Function
set_objective(  - (sum_over(y[i] * log(PI[l]) * p_il[i,l] + (1-y[i]) * log(1-PI[l]) * p_il[i,l],i=1:n,l=1:length(PI)))
,sense = "min") %>%
solve_model(with_ROI(solver = "glpk"))
# Lambda in obj
#
t2 = Sys.time()
time.diff <- t2 - t1
# Extract Coefficients
beta <- MILP_V2 %>% get_solution(beta[j])
s <- MILP_V2 %>% get_solution(s[i])
beta
s
lapply(1:10, function(i) t(as.matrix(beta[,3])) %*% as.matrix(X[i,]))
s_check <- lapply(1:10, function(i) t(as.matrix(beta[,3])) %*% as.matrix(X[i,]))
View(s_check)
s_check <- unlist(lapply(1:10, function(i) t(as.matrix(beta[,3])) %*% as.matrix(X[i,])))
s
s_check
#
zik <- MILP_V2 %>% get_solution(z_ik[i,k])
zik %>% filter(value==1)
zik %>% group_by(i) %>% summarise(w <- sum(value))
zik %>% filter(value==1)
pil <- MILP_V2 %>% get_solution(p_il[i,l])
pil %>% group_by(i) %>% summarise(sum_p = sum(value))
pil %>% filter(value==1)
PI(1)
PI[1]
PI[98]
# Only works when there's a column with all being 1. then that j is -50 others are 0
MILP_V2$objective_value
zkl %>% filter(value==1)
zkl <- MILP_V2 %>% get_solution(z_kl[k,l])
zkl %>% group_by(k) %>% summarise(w <- sum(value))
zkl %>% filter(value==1)
# MILP Version 2
# Testing run with smaller sample sized datasets
# Small data stored at small_data
files <- list.files("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data")
df <- read.csv(paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data/",files[10]))
# Set data matrix
# works out fine for 1:5, errors when trying yo increase sample size
df <- df[1:10,1:5]
y <- df[[1]]
X <- as.matrix(df[,2:ncol(df)])
# Warm start solution
n = nrow(X)
p = ncol(X)
M = 1000 #
Lambda0 = 0
# Score Pool
SK_pool <- c((-5*p) : (5*p)) # Determined by lb and ub of beta
# Probability pool
PI <- seq(0,1,length=100) # Equally spaced between 0,1, length = 100
# Delete 0 and 1 so that obj can take log
PI <- PI[-c(1,100)]
t1 = Sys.time()
# Model description
MILP_V2 <- MIPModel() %>%
# Integer coefficients for attributes
add_variable(beta[j], j=1:p, type = 'integer') %>%
# Predicted Risk Score from the integer coefficients
add_variable(s[i], i= 1:n, type = 'integer') %>%
# Exchanged this line on 11.8.2023
add_constraint(sum_over(beta[j]*X[i,j], j=1:p) - s[i] == 0,i=1:n) %>%
# Indicator of S_i = k, k: one potential score from the score pool
add_variable(z_ik[i,k], i=1:n, k=1:length(SK_pool), type = 'binary') %>%
add_constraint(sum_over(z_ik[i,k], k = 1:length(SK_pool)) == 1, i=1:n) %>%
# old
add_constraint(s[i] - SK_pool[k] <= M * (1-z_ik[i,k]), i=1:n,k=1:length(SK_pool)) %>%
add_constraint(s[i] - SK_pool[k] >= -M * (1-z_ik[i,k]), i=1:n,k=1:length(SK_pool)) %>%
# new
#add_constraint((1-z_ik[i,k]) / (s[i] - SK_pool[k]) <= 1/M , i=1:n,k=1:length(SK_pool)) %>%
#add_constraint((1-z_ik[i,k]) / (s[i] - SK_pool[k]) >= -1/M, i=1:n,k=1:length(SK_pool)) %>%
# Indicator of score k assigned to prob pi_l
add_variable(z_kl[k,l], k=1:length(SK_pool), l=1:length(PI), type = 'binary')
# higher K is associated with higher probabilities
# Add constraints in nested loops
for (k in 2:length(SK_pool)) { # Start from 2 since you're using k-1
for (l in 1:(length(PI)-1)) {
for (lh in (l+1):length(PI)) {
MILP_V2 <- MILP_V2 %>%
add_constraint(z_kl[k, l] <= 1 - z_kl[k-1, lh])
}
}
}
MILP_V2 <- MILP_V2 %>%
# each k is assigned to exactly 1 probs
add_constraint(sum_over(z_kl[k,l], l=1:length(PI)) == 1,k=1:length(SK_pool)) %>%
# Indicator of point i assigned with prob pi_l
add_variable(p_il[i,l], i=1:n, l=1:length(PI),type = 'binary') %>%
# old
add_constraint(p_il[i,l] >= z_kl[k,l] + z_ik[i,k] - 1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# new
#add_constraint(p_il[i,l] - z_kl[k,l] - z_ik[i,k] >= -1, i=1:n, k=1:length(SK_pool), l=1:length(PI)) %>%
# Each i have exactly one probs
add_constraint(sum_over(p_il[i,l], l=1:length(PI)) == 1, i=1:n) %>%
#Penalty Expression
#add_variable(lambda[j],j=1:p,type = 'binary') %>%
#add_constraint(beta[j] <= M*lambda[j], j=1:p) %>%
#add_constraint(beta[j] <= -M*lambda[j], j=1:p) %>%
# Objective Function
set_objective(  - (sum_over(y[i] * log(PI[l]) * p_il[i,l] + (1-y[i]) * log(1-PI[l]) * p_il[i,l],i=1:n,l=1:length(PI)))
,sense = "min") %>%
solve_model(with_ROI(solver = "glpk"))
# Lambda in obj
#
t2 = Sys.time()
time.diff <- t2 - t1
# Extract Coefficients
beta <- MILP_V2 %>% get_solution(beta[j])
s <- MILP_V2 %>% get_solution(s[i])
s_check <- unlist(lapply(1:10, function(i) t(as.matrix(beta[,3])) %*% as.matrix(X[i,])))
beta
s
#
zik <- MILP_V2 %>% get_solution(z_ik[i,k])
MILP_V2
setwd("~/Documents/GitHub/Risk_Model_Research/R")
# Testing run with smaller sample sized datasets
# Small data stored at small_data
files <- list.files("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data")
df <- read.csv(paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/MILP/data/",files[10]))
files[10]
# Set data matrix
# works out fine for 1:5, errors when trying yo increase sample size
df <- df[10:20,1:5]
View(df)
# Set data matrix
# works out fine for 1:5, errors when trying yo increase sample size
df <- df[10:20,1:5]
get_wd()
library(dplyr)
getwd()
simulate_data <- function(n, p1, p2, eps=0){
# n: number of observations
# p1: number of variables with a coefficient between 0 and 1
# p2: number of variables with a coefficient between 1 and 5
# covariates
x <- matrix(0, nrow=n, ncol=(p1+p2))
for (i in 1:(p1+p2)){
x[,i] <- rbinom(n, 1, runif(1))
}
# coefficients
coef <- runif(p1)
coef <- c(coef, runif(p2,min=1,max=5))
vals <- x %*% coef
intercept <- -mean(vals)
# outcome
vals <- vals+intercept+rnorm(n,0,eps*sd(vals))
probs <- exp(vals)/(1+exp(vals))
y <- rbinom(n, 1, prob = probs)
return(list(x=x,y=y,coef=coef, intercept =intercept))
}
gen_data <- function(n, p1, p2, eps, filename){
# Generates data and saves two files - one with data, one with coefficient vals
data <- simulate_data(n, p1, p2, eps)
# data file
df <- as.data.frame(data$x)
df$y <- data$y
df <- df %>%
select(y, everything())
write.csv(df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat",filename,"_data.csv"), row.names=FALSE)
# coefficients file
coef_df <- data.frame(names = c("Intercept",names(df)[1:(p1+p2)]),
vals = c(data$intercept, data$coef))
write.csv(coef_df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat",filename,"_coef.csv"), row.names=FALSE)
}
library(dplyr)
simulate_data <- function(n, p1, p2, eps=0){
# n: number of observations
# p1: number of variables with a coefficient between 0 and 1
# p2: number of variables with a coefficient between 1 and 5
# covariates
x <- matrix(0, nrow=n, ncol=(p1+p2))
for (i in 1:(p1+p2)){
x[,i] <- rbinom(n, 1, runif(1))
}
# coefficients
coef <- runif(p1)
coef <- c(coef, runif(p2,min=1,max=5))
vals <- x %*% coef
intercept <- -mean(vals)
# outcome
vals <- vals+intercept+rnorm(n,0,eps*sd(vals))
probs <- exp(vals)/(1+exp(vals))
y <- rbinom(n, 1, prob = probs)
return(list(x=x,y=y,coef=coef, intercept =intercept))
}
gen_data <- function(n, p1, p2, eps, filename){
# Generates data and saves two files - one with data, one with coefficient vals
data <- simulate_data(n, p1, p2, eps)
# data file
df <- as.data.frame(data$x)
df$y <- data$y
df <- df %>%
select(y, everything())
write.csv(df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat",filename,"_data.csv"), row.names=FALSE)
# coefficients file
coef_df <- data.frame(names = c("Intercept",names(df)[1:(p1+p2)]),
vals = c(data$intercept, data$coef))
write.csv(coef_df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat",filename,"_coef.csv"), row.names=FALSE)
}
# Example of generating data and saving
set.seed(5)
n = c(20,50,100)
p1 = c(5,6,7,8,9,10)
p2 = c(1,2,3,4,5)
for (j in 1:length(n)){
for (k in 1:length(p1)) {
for (l in 1:length(p2)) {
for (eps in c(0, 0.3, 0.5, 1.0)){
for (i in 1:10){
gen_data(n[j], p1[k], p2[k], eps,
paste0("sim",n[j],'_',p1[k],"_",p2[k],"_",as.integer(10*eps),"_",i))
}
}
}
}
}
library(dplyr)
simulate_data <- function(n, p1, p2, eps=0){
# n: number of observations
# p1: number of variables with a coefficient between 0 and 1
# p2: number of variables with a coefficient between 1 and 5
# covariates
x <- matrix(0, nrow=n, ncol=(p1+p2))
for (i in 1:(p1+p2)){
x[,i] <- rbinom(n, 1, runif(1))
}
# coefficients
coef <- runif(p1)
coef <- c(coef, runif(p2,min=1,max=5))
vals <- x %*% coef
intercept <- -mean(vals)
# outcome
vals <- vals+intercept+rnorm(n,0,eps*sd(vals))
probs <- exp(vals)/(1+exp(vals))
y <- rbinom(n, 1, prob = probs)
return(list(x=x,y=y,coef=coef, intercept =intercept))
}
gen_data <- function(n, p1, p2, eps, filename){
# Generates data and saves two files - one with data, one with coefficient vals
data <- simulate_data(n, p1, p2, eps)
# data file
df <- as.data.frame(data$x)
df$y <- data$y
df <- df %>%
select(y, everything())
write.csv(df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat/",filename,"_data.csv"), row.names=FALSE)
# coefficients file
coef_df <- data.frame(names = c("Intercept",names(df)[1:(p1+p2)]),
vals = c(data$intercept, data$coef))
write.csv(coef_df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat/",filename,"_coef.csv"), row.names=FALSE)
}
# Example of generating data and saving
set.seed(5)
n = c(20,50,100)
p1 = c(5,6,7,8,9)
p2 = c(1,2,3,4,5)
for (j in 1:length(n)){
for (k in 1:length(p1)) {
for (l in 1:length(p2)) {
for (eps in c(0, 0.3, 0.5, 1.0)){
for (i in 1:10){
gen_data(n[j], p1[k], p2[k], eps,
paste0("sim",'_',n[j],'_',p1[k],"_",p2[l],"_",as.integer(10*eps),"_",i))
}
}
}
}
}
library(dplyr)
simulate_data <- function(n, p1, p2, eps=0){
# n: number of observations
# p1: number of variables with a coefficient between 0 and 1
# p2: number of variables with a coefficient between 1 and 5
# covariates
x <- matrix(0, nrow=n, ncol=(p1+p2))
for (i in 1:(p1+p2)){
x[,i] <- rbinom(n, 1, runif(1))
}
# coefficients
coef <- runif(p1)
coef <- c(coef, runif(p2,min=1,max=5))
vals <- x %*% coef
intercept <- -mean(vals)
# outcome
vals <- vals+intercept+rnorm(n,0,eps*sd(vals))
probs <- exp(vals)/(1+exp(vals))
y <- rbinom(n, 1, prob = probs)
return(list(x=x,y=y,coef=coef, intercept =intercept))
}
gen_data <- function(n, p1, p2, eps, filename){
# Generates data and saves two files - one with data, one with coefficient vals
data <- simulate_data(n, p1, p2, eps)
# data file
df <- as.data.frame(data$x)
df$y <- data$y
df <- df %>%
select(y, everything())
write.csv(df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat/",filename,"_data.csv"), row.names=FALSE)
# coefficients file
coef_df <- data.frame(names = c("Intercept",names(df)[1:(p1+p2)]),
vals = c(data$intercept, data$coef))
write.csv(coef_df, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/simdat/",filename,"_coef.csv"), row.names=FALSE)
}
# Example of generating data and saving
set.seed(5)
n = c(20,50,100)
p1 = c(5,6,7,8,9)
p2 = c(1,2,3,4,5)
for (j in 1:length(n)){
for (k in 1:length(p1)) {
for (l in 1:length(p2)) {
for (eps in c(0, 0.3, 0.5, 1.0)){
for (i in 1:10){
gen_data(n[j], p1[k], p2[k], eps,
paste0("sim",'_',n[j],'_',p1[k],"_",p2[l],"_",as.integer(10*eps),"_",i))
}
}
}
}
}
source('risk.R')
run_experiments <- function(my_path){
#' Risk model algorithm experiments
#'
#' Iterates through all csv files in the path and runs risk mod
#' @param my_path character path to folder of csv files (assumes
#' files are stored as (x)_data.csv and (x)_weights.csv)
#' @return results are saved as a csv file results_R.csv in the same folder
# Files in path
files <- list.files(my_path)
results <- data.frame(data = character(), n = numeric(), p = numeric(),
lambda0 = numeric(), non_zeros = numeric(),
med_abs = numeric(), max_abs = numeric(),
acc = numeric(), sens = numeric(), spec = numeric(),
sec = numeric())
# Iterate through files
for (f in files){
if (length(grep("_data.csv", f)) == 0) next
# Print for ease
print(paste0(my_path,f))
# Read in data
df <- read.csv(paste0(my_path,f))
y <- df[[1]]
X <- as.matrix(df[,2:ncol(df)])
X <- cbind(rep(1,nrow(X)), X) # adds intercept column
# Add weights file if needed
weights <- rep(1, nrow(X))
weights_file <- paste0(substr(f,1,nchar(f)-8),"_weights.csv")
if (file.exists(weights_file)){
weights <- read.csv(weights_file)
weights <- weights[[1]]
}
# Run algorithm to get risk model
# Testing for lambda_min as lambda 0
t1 <- Sys.time()
#lambda0 <- cv_risk_mod(X, y, weights=weights, nfolds = 5)$lambda_min # chenge for cv
#lambda1se <- cv_risk_mod(X, y, weights=weights, nfolds = 5)$lambda_1se
mod <- risk_mod(X, y, weights=weights, lambda0 = 0) # change for cv
t2 <- Sys.time()
# Get evaluation metrics
time_secs <- t2 - t1
res_metrics <- get_metrics(mod)
non_zeros <- sum(mod$beta[-1] != 0)
med_abs <- median(abs(mod$beta[-1]))
max_abs <- max(abs(mod$beta[-1]))
# Add row to data frame
file_row <- data.frame(data=f, n = nrow(X), p = ncol(X), lambda0 = 0,
non_zeros = non_zeros, med_abs = med_abs, max_abs = max_abs,
acc = res_metrics$acc, sens = res_metrics$sens,
spec = res_metrics$spec, sec = time_secs) # change for cv
results <- rbind(results, file_row)
}
write.csv(results, paste0("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/sim_newalg/", "ncd_cv0_R_loop.csv"), row.names=FALSE)
}
run_experiments("/Users/oscar/Documents/GitHub/Risk_Model_Research/ncd_milp/sim_newalg/")
