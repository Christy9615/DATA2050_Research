---
title: "Results Summary 2023.10.11"
author: "Yu Yan"
date: "2023-10-11"
header-includes:
  - \usepackage{placeins}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(error = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)

#knitr::opts_chunk$set(fig.width=8, fig.height=4) 
library(tidyverse)
library(kableExtra)
library(mice)
library(gtsummary)
library(psych)
library(ggridges)
library(writexl)
```

```{r echo=F}
#This document includes simulation results summary of 2023.10.11. The simulation was about testing performance of cyclical coordinate descent risk score algorithm on newly generated data. The new generated data incorporated more variability in the relationship between covariate as we applied exponential correlation and signal-to-noise ratio while generate simulated data. We tested the performance in three settings: no cross validation, cross validation then select lambda_min as lambda0 in the risk model, and cross validation then select lambda_1se as lambda0 in the risk model.

#The new generation of simulated data are generated as follows. We created a simulation function with the following input parameters:n,p1,p2,p3,rho,snr. The feature set has n*p(p1+p2+p3) dimensions, sampled from multivariate Gaussian with exponential correlation between columns, where p1 denotes number of variables with coefficient between  0 and 1, p2 denotes number of variables with coefficient between  1 and 5, and p3 denotes number of variables with coefficient of 0. The exponential correlation between columns is denoted by rho, defaulting 0.5. During the generation process, outcome variable is generated as y = xb + epsilon, where b is a vector with 'supp_size', defined as randomly chosen entries equal to 1 and the rest equal to 0. For a more comprehensive evaluation of the current risk model, we introduced some random noise to the simulated data to see if it catches the correct feature sets. We establish this by incorporating a signal to noise ratio parameter in the data simulation function as snr. It is reflected by creating random noise epsilon when generating the outcome variable in each calling of the function. In conclusion, by setting each parameters, the function outputs a list containing four elements: feature matrix x, outcome variable y, coefficnets to each feature, and the intercept. 

#This simulation task involved using simulated data as above to test the current algorithm. The goal is to see how the running time of the algorithm increases with respect to varying dimensions and whether it finds the correct structure of the data with varying degree of noise. The varying conditions were established by setting the parameters as followings: N = 1000, P = 10, 50, 100, P1 = 0, p2 = 10%, 50% or 90% of P, Rho = 0.1, 0.5, 0.9,SNR = 5, for each unique combination setting of the parameters,we created 10 data frames for each setting
```

# Simulation Results Summary (Date: 2023.10.11)

In this report, we provide a comprehensive overview of simulation results conducted on October 11, 2023, focusing on the evaluation of the cyclical coordinate descent risk score algorithm's performance. The simulation aimed to assess the algorithm's efficacy in handling complex, real-world data scenarios by introducing enhanced variability in the relationship between covariates.

## Simulation Methodology:

The simulated data were generated using a sophisticated simulation function tailored for statistical robustness. The function accepted various input parameters, including sample size (\(n\)), the number of variables with coefficients between 0 and 1 (\(p_1\)), variables with coefficients between 1 and 5 (\(p_2\)), and variables with coefficients equal to 0 (\(p_3\)). The feature set, structured as \(n \times p \times (p_1 + p_2 + p_3)\), was meticulously sampled from a multivariate Gaussian distribution. Notably, the correlation between columns was introduced through an exponential correlation mechanism, characterized by the parameter \(\rho\) (defaulting to 0.5). 

In the generation process, the outcome variable (\(y\)) was modeled as \(y = xb + \epsilon\), where \(b\) represented a vector with 'supp_size' elements, randomly set to 1 and the remaining set to 0. To emulate real-world complexities, random noise (\(\epsilon\)) was incorporated. The magnitude of this noise, controlled by the signal-to-noise ratio parameter (SNR), played a pivotal role in evaluating the algorithm's resilience in noisy environments.

## Simulation Settings and Variability Parameters:

The simulation was conducted under three distinct settings to comprehensively analyze the algorithm's behavior:

1. **No Cross Validation:** The algorithm's performance was analyzed without employing cross-validation.
2. **Cross Validation with \(\lambda_{\text{min}}\):** Cross-validation was employed, and \(\lambda_{\text{min}}\) was selected as \(\lambda_0\) in the risk model.
3. **Cross Validation with \(\lambda_{\text{1se}}\):** Cross-validation was applied, and \(\lambda_{\text{1se}}\) was chosen as \(\lambda_0\) in the risk model.

The simulation spanned various combinations of parameters, including a sample size of \(N = 1000\), varying feature dimensions (\(P = 10\), 50, 100), proportions of coefficients (\(P_1 = 0\), \(p_2 = 10\%\), \(50\%\), \(90\%\) of \(P\)), and correlation strengths (\(\rho = 0.1\), 0.5, 0.9). Additionally, the SNR parameter was set to 5 to represent different levels of noise in the data. For each unique combination, ten data frames were generated for meticulous analysis.

## Background Significance:

Understanding the algorithm's behavior under diverse and challenging conditions is crucial for real-world applications. By introducing intricate relationships and noise structures, we aimed to simulate scenarios encountered in complex datasets. This comprehensive evaluation provides insights not only into the algorithm's accuracy but also its stability and adaptability in addressing real-world complexities.

```{r eval=F}
# Do not Run, script
ncd_cv_R_newdat_min = ncd_cv_R_newdat_min %>% mutate(p2 = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[3])
  })), 
                                   p3 = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[4])
  })),
                                   rho = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[5])
  })),
                                   rep = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[6])
  })))

levels(ncd_cv_R_newdat_min$p2)

ncd_cv_R_newdat_min %>% select(p2,rho,sec) %>% 
  tbl_strata(
    strata = p2,
    .tbl_fun =
      ~ .x %>%
      tbl_summary(by = rho,
        missing_text = "NA",
        type = list(sec ~ 'continuous'),
    statistic = all_continuous() ~ "{mean}") %>%
      add_n() ,
    .header = "**{strata}**"  
  ) 

```

```{r}
ncd_cv_R_newdat_min <- read_csv('ncd_cv_R_newdat_min.csv')
ncd_cv_R_newdat_min = ncd_cv_R_newdat_min %>% mutate(p2 = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[3])
  })), 
                                   p3 = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[4])
  })),
                                   rho = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[5])
  })),
                                   rep = unlist(lapply(ncd_cv_R_newdat_min$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[6])
  })))


min = ncd_cv_R_newdat_min %>% group_by(p-1,p2,rho) %>% summarise(lambda0_mean = mean(lambda0),
                                                           non_zero_mean = mean(non_zeros),
                                                           sec_mean = mean(sec),
                                                           acc_mean = mean(acc),
                                                           sens_mean = mean(sens),
                                                           spec_mean = mean(spec))

names(min)[1] = 'p'
min$p2p = as.numeric(min$p2) / as.numeric(min$p)
```

```{r}
ncd_cv_R_newdat_1se <- read_csv('ncd_cv_R_newdat_1se.csv')
ncd_cv_R_newdat_1se = ncd_cv_R_newdat_1se %>% mutate(p2 = unlist(lapply(ncd_cv_R_newdat_1se$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[3])
  })), 
                                   p3 = unlist(lapply(ncd_cv_R_newdat_1se$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[4])
  })),
                                   rho = unlist(lapply(ncd_cv_R_newdat_1se$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[5])
  })),
                                   rep = unlist(lapply(ncd_cv_R_newdat_1se$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[6])
  })))

se = ncd_cv_R_newdat_1se %>% group_by(p-1,p2,rho) %>% summarise(lambda0_mean = mean(lambda0),
                                                           non_zero_mean = mean(non_zeros),
                                                           sec_mean = mean(sec),
                                                           acc_mean = mean(acc),
                                                           sens_mean = mean(sens),
                                                           spec_mean = mean(spec))

names(se)[1] = 'p'
se$p2p = as.numeric(se$p2) / as.numeric(se$p)

```

```{r}
ncd_nocv_newdat <- read_csv('ncd_nocv_newdat.csv')
ncd_nocv_newdat = ncd_nocv_newdat %>% mutate(p2 = unlist(lapply(ncd_nocv_newdat$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[3])
  })), 
                                   p3 = unlist(lapply(ncd_nocv_newdat$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[4])
  })),
                                   rho = unlist(lapply(ncd_nocv_newdat$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[5])
  })),
                                   rep = unlist(lapply(ncd_nocv_newdat$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[6])
  })))

r = ncd_nocv_newdat %>% group_by(p-1,p2,rho) %>% summarise(lambda0_mean = mean(lambda0),
                                                           non_zero_mean = mean(non_zeros),
                                                           sec_mean = mean(sec),
                                                           acc_mean = mean(acc),
                                                           sens_mean = mean(sens),
                                                           spec_mean = mean(spec))

names(r)[c(1,4)] = c('p','lambda0')
r$p2p = as.numeric(r$p2) / as.numeric(r$p)

```


# Non_zero comparison

One main goal of this simulation experiment is to see if the current algorithm finds the correct structure in the data presented. Our expectation in this goal is that the results are sensitive to randomness intrduced during data simulation phase. In specific, the data were generated with different number of p1,p2, and p3 each represent the number of variables(feature) with designated coefficients to the outcome. Among them, P2 indicate the number of non-zero variables. The nature of our algorithm should be able to identify the this number as the number of non-zero coefficients in the final outcome risk model since there is an L0 error term added that penalizes non-significant variables and eliminate their impact in the end. So our result should show that this pattern of matching non-zero coefficients and p2. Since there's different rho values, we expect that as rho increase, the algorithm is hard to identify the pattern as its performance are interpreted by the noises. 
From the graph, we can see that as rho increase, the model's performance in this dimension gets worse. When rho is 0.1, the coefficient of fitted line is very close to 1 meaning it finds very well the number of non-zero coefficients. And as rho increases, it performs badly. The performance is consistently better when using lambda_min as the lambda_0 in comparison to using lambda_se.

```{r}
nonz_Dat <- as.data.frame(cbind(min$p,min$p2,min$p2p,min$rho,min$non_zero_mean,se$non_zero_mean)) %>% set_names(c('p','p2','p2p','rho','min','se'))
library(ggpmisc)

rho.labs <- c("rho=0.1", "rho=0.5", "rho=0.9")
names(rho.labs) <- c("0.1", "0.5", "0.9")

nonz_Dat  %>% pivot_longer(c(min,se), names_to = 'type',values_to = 'non_zero') %>% 
  ggplot(aes(x=as.numeric(p2),y=as.numeric(non_zero),color=type)) + geom_smooth(se=F) +
  scale_linetype_manual(values = c("0.1" = "solid", "0.5" = "dashed",'0.9' = 'dotted')) +
  facet_grid(~rho,labeller = labeller(rho = rho.labs)) + 
  stat_poly_line(formula = y ~ x) +
  stat_poly_eq(formula = y ~ x, aes(label = after_stat(eq.label))) +
  geom_point() + labs(x='P2',y='Non_zero',color='CV Type',title = 'Summary of Non_zero')

```

# Running time Comparison
The following graph summaries running time of the models stratified by different rho, P2 proportion and cv types.Higher P2 proportion and higher rho lead to longer running time. 

```{r}
time_dat <- as.data.frame(cbind(min$p,min$p2p,min$rho,min$sec_mean,se$sec_mean,r$sec_mean)) %>% set_names(c('p','p2','rho','min','se','nocv'))

time_dat  %>% pivot_longer(c(min,se,nocv), names_to = 'type',values_to = 'run_time') %>% 
  ggplot(aes(x=as.numeric(p),y=as.numeric(run_time),color=type,linetype=as.factor(p2))) + geom_smooth(se=F) +
  scale_linetype_manual(values = c("0.1" = "solid", "0.5" = "dashed",'0.9' = 'dotted')) +
  facet_grid(~rho,labeller = labeller(rho = rho.labs)) + labs(x='P',y='Running Time',color='CV Type',linetype='P2 Proportion',title = 'Summary of Running Time')
```


# Accuracy comparison
The following graph summaries accuracy of the models stratified by different rho, P2 proportion and CV types. We do not observe much significant difference in the accuracy of the prediction in terms of different parameters. This validates the robustness of the model.

```{r}
acc_dat <- as.data.frame(cbind(min$p,min$p2p,min$rho,min$acc_mean,se$acc_mean,r$acc_mean)) %>% set_names(c('p','p2','rho','min','se','nocv'))

rho.labs <- c("rho=0.1", "rho=0.5", "rho=0.9")
names(rho.labs) <- c("0.1", "0.5", "0.9")

acc_dat  %>% pivot_longer(c(min,se,nocv), names_to = 'type',values_to = 'acc') %>% 
  ggplot(aes(x=as.numeric(p),y=as.numeric(acc),color=type,linetype=as.factor(p2))) + geom_smooth(se=F) +
  scale_linetype_manual(values = c("0.1" = "solid", "0.5" = "dashed",'0.9' = 'dotted')) +
  facet_grid(~rho,labeller = labeller(rho = rho.labs)) + labs(x='P',y='Accuracy',color='CV Type',linetype='P2 Proportion',title = 'Summary of accuracy')

```

# Parallel Computation
In this section, the possibility of conducting cross validation using parallel computaion was added to the existing version with a new parameter of the function for the users' own choice. We would like to see how does the performance change with respect to parallel vs non parallel
```{r}
ncd_cv_R_newdat_1se_para <- read.csv('ncd_cv_R_newdat_1se_para.csv')
ncd_cv_R_newdat_min_para <- read.csv('ncd_cv_R_newdat_min_para.csv')
```


```{r}
ncd_cv_R_newdat_min_para = ncd_cv_R_newdat_min_para %>% mutate(p2 = unlist(lapply(ncd_cv_R_newdat_min_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[3])
  })), 
                                   p3 = unlist(lapply(ncd_cv_R_newdat_min_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[4])
  })),
                                   rho = unlist(lapply(ncd_cv_R_newdat_min_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[5])
  })),
                                   rep = unlist(lapply(ncd_cv_R_newdat_min_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[6])
  })))

min_para = ncd_cv_R_newdat_min_para %>% group_by(p-1,p2,rho) %>% summarise(lambda0_mean = mean(lambda0),
                                                           non_zero_mean = mean(non_zeros),
                                                           sec_mean = mean(sec),
                                                           acc_mean = mean(acc),
                                                           sens_mean = mean(sens),
                                                           spec_mean = mean(spec))

names(min_para)[1] = 'p'
min_para$p2p = as.numeric(min_para$p2) / as.numeric(min_para$p)

```

```{r}
ncd_cv_R_newdat_1se_para = ncd_cv_R_newdat_1se_para %>% mutate(p2 = unlist(lapply(ncd_cv_R_newdat_1se_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[3])
  })), 
                                   p3 = unlist(lapply(ncd_cv_R_newdat_1se_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[4])
  })),
                                   rho = unlist(lapply(ncd_cv_R_newdat_1se_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[5])
  })),
                                   rep = unlist(lapply(ncd_cv_R_newdat_1se_para$data, function(input_string) {
  split_string <- unlist(strsplit(input_string, "_"))
  return(split_string[6])
  })))

se_para = ncd_cv_R_newdat_1se_para %>% group_by(p-1,p2,rho) %>% summarise(lambda0_mean = mean(lambda0),
                                                           non_zero_mean = mean(non_zeros),
                                                           sec_mean = mean(sec),
                                                           acc_mean = mean(acc),
                                                           sens_mean = mean(sens),
                                                           spec_mean = mean(spec))

names(se_para)[1] = 'p'
se_para$p2p = as.numeric(se_para$p2) / as.numeric(se_para$p)

```

# Average time comparison
From the graph, we can see there's a huge drop in the average running with parallel computation enabled. 
```{r}
time_dat_para <- as.data.frame(cbind(min$p,min$p2p,min$rho,min$sec_mean,min_para$sec_mean)) %>% set_names(c('p','p2','rho','min','min_para'))

time_dat_para  %>% pivot_longer(c(min,min_para), names_to = 'type',values_to = 'run_time') %>% 
  ggplot(aes(x=as.numeric(p),y=as.numeric(run_time),color=type)) + geom_smooth(se=F) +
  scale_linetype_manual(values = c("0.1" = "solid", "0.5" = "dashed",'0.9' = 'dotted')) +
  facet_grid(~rho,labeller = labeller(rho = rho.labs)) + labs(x='P',y='Running Time',color='CV Type',title = 'Summary of Running Time Using Parallel Computation')
```

```{r eval=F}
# Export
tables <- list(tbl1 = r, tbl2 = min, tbl3=se)
write_xlsx(tables, path = "summary.xlsx")
```

